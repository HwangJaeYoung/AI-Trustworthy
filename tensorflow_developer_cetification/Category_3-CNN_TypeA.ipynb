{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"hhP4SrhClB4c","executionInfo":{"status":"ok","timestamp":1643893151869,"user_tz":-540,"elapsed":5288,"user":{"displayName":"JaeYoung Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08071223562055378805"}}},"outputs":[],"source":["import urllib.request\n","import zipfile\n","import numpy as np\n","from IPython.display import Image\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"yli961eDQEfi","executionInfo":{"status":"ok","timestamp":1643893157177,"user_tz":-540,"elapsed":5314,"user":{"displayName":"JaeYoung Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08071223562055378805"}}},"outputs":[],"source":["url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n","urllib.request.urlretrieve(url, 'rps.zip')\n","local_zip = 'rps.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('tmp/')\n","zip_ref.close()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"z1UlXIVJfgbg","executionInfo":{"status":"ok","timestamp":1643893157178,"user_tz":-540,"elapsed":23,"user":{"displayName":"JaeYoung Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08071223562055378805"}}},"outputs":[],"source":["# training dir\n","TRAINING_DIR = \"tmp/rps/\""]},{"cell_type":"code","execution_count":4,"metadata":{"id":"HzANCu_Ffgej","executionInfo":{"status":"ok","timestamp":1643893157178,"user_tz":-540,"elapsed":21,"user":{"displayName":"JaeYoung Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08071223562055378805"}}},"outputs":[],"source":["training_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest', \n","    validation_split=0.2\n","    )"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":446,"status":"ok","timestamp":1643893157604,"user":{"displayName":"JaeYoung Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08071223562055378805"},"user_tz":-540},"id":"AYiBkLPlfgg5","outputId":"d38e957f-3e41-48f8-daa1-94ed8a4fa862"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2016 images belonging to 3 classes.\n"]}],"source":["training_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n","                                                          batch_size=32, \n","                                                          target_size=(150, 150), \n","                                                          class_mode='categorical', \n","                                                          subset='training',\n","                                                         )"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1643893157605,"user":{"displayName":"JaeYoung Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08071223562055378805"},"user_tz":-540},"id":"ayvxLGxefgkC","outputId":"0b0ec6b4-ce2a-4aac-942d-97752df1045f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 504 images belonging to 3 classes.\n"]}],"source":["validation_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n","                                                          batch_size=32, \n","                                                          target_size=(150, 150), \n","                                                          class_mode='categorical',\n","                                                          subset='validation', \n","                                                         )"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4006,"status":"ok","timestamp":1643893161607,"user":{"displayName":"JaeYoung Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08071223562055378805"},"user_tz":-540},"id":"RMXz0PrOfgmX","outputId":"b27684c7-5a93-4eb2-8bae-39e774d355c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 148, 148, 64)      1792      \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 74, 74, 64)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 72, 72, 64)        36928     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 7, 7, 128)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 6272)              0         \n","                                                                 \n"," dropout (Dropout)           (None, 6272)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               3211776   \n","                                                                 \n"," dense_1 (Dense)             (None, 3)                 1539      \n","                                                                 \n","=================================================================\n","Total params: 3,473,475\n","Trainable params: 3,473,475\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model = Sequential([\n","    # Conv2D, MaxPooling2D 조합으로 층을 쌓습니다. 첫번째 입력층의 input_shape은 (150, 150, 3)으로 지정합니다.\n","    Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n","    MaxPooling2D(2, 2), \n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2), \n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2), \n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2), \n","    # 2D -> 1D로 변환을 위하여 Flatten 합니다.\n","    Flatten(), \n","    # 과적합 방지를 위하여 Dropout을 적용합니다.\n","    Dropout(0.5),\n","    Dense(512, activation='relu'),\n","    # Classification을 위한 Softmax \n","    # 출력층의 갯수는 클래스의 갯수와 동일하게 맞춰줍니다 (3개), activation도 잊지마세요!\n","    Dense(3, activation='softmax'),\n","])\n","model.summary()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"npueewNFfgow","executionInfo":{"status":"ok","timestamp":1643893161607,"user_tz":-540,"elapsed":8,"user":{"displayName":"JaeYoung Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08071223562055378805"}}},"outputs":[],"source":["model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"m-qiHqqkgE2S","executionInfo":{"status":"ok","timestamp":1643893161608,"user_tz":-540,"elapsed":7,"user":{"displayName":"JaeYoung Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08071223562055378805"}}},"outputs":[],"source":["checkpoint_path = \"tmp_checkpoint.ckpt\"\n","checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n","                             save_weights_only=True, \n","                             save_best_only=True, \n","                             monitor='val_loss', \n","                             verbose=1)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"pfXuSEAtgE4G","executionInfo":{"status":"ok","timestamp":1643893161608,"user_tz":-540,"elapsed":7,"user":{"displayName":"JaeYoung Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08071223562055378805"}}},"outputs":[],"source":["epochs=25"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4c-DowuRgIHc","outputId":"b8a34b53-8c46-43df-8504-afc9c527a656","executionInfo":{"status":"ok","timestamp":1643893794215,"user_tz":-540,"elapsed":632613,"user":{"displayName":"JaeYoung Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08071223562055378805"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","63/63 [==============================] - ETA: 0s - loss: 1.0551 - acc: 0.4187\n","Epoch 00001: val_loss improved from inf to 0.98272, saving model to tmp_checkpoint.ckpt\n","63/63 [==============================] - 37s 376ms/step - loss: 1.0551 - acc: 0.4187 - val_loss: 0.9827 - val_acc: 0.5357\n","Epoch 2/25\n","63/63 [==============================] - ETA: 0s - loss: 0.6997 - acc: 0.6806\n","Epoch 00002: val_loss improved from 0.98272 to 0.85639, saving model to tmp_checkpoint.ckpt\n","63/63 [==============================] - 23s 367ms/step - loss: 0.6997 - acc: 0.6806 - val_loss: 0.8564 - val_acc: 0.6865\n","Epoch 3/25\n","63/63 [==============================] - ETA: 0s - loss: 0.4779 - acc: 0.8070\n","Epoch 00003: val_loss improved from 0.85639 to 0.72493, saving model to tmp_checkpoint.ckpt\n","63/63 [==============================] - 25s 396ms/step - loss: 0.4779 - acc: 0.8070 - val_loss: 0.7249 - val_acc: 0.7361\n","Epoch 4/25\n","63/63 [==============================] - ETA: 0s - loss: 0.3076 - acc: 0.8770\n","Epoch 00004: val_loss improved from 0.72493 to 0.55857, saving model to tmp_checkpoint.ckpt\n","63/63 [==============================] - 23s 367ms/step - loss: 0.3076 - acc: 0.8770 - val_loss: 0.5586 - val_acc: 0.7877\n","Epoch 5/25\n","63/63 [==============================] - ETA: 0s - loss: 0.1994 - acc: 0.9311\n","Epoch 00005: val_loss did not improve from 0.55857\n","63/63 [==============================] - 23s 362ms/step - loss: 0.1994 - acc: 0.9311 - val_loss: 1.0007 - val_acc: 0.6429\n","Epoch 6/25\n","63/63 [==============================] - ETA: 0s - loss: 0.1681 - acc: 0.9449\n","Epoch 00006: val_loss did not improve from 0.55857\n","63/63 [==============================] - 23s 364ms/step - loss: 0.1681 - acc: 0.9449 - val_loss: 0.5860 - val_acc: 0.7421\n","Epoch 7/25\n","63/63 [==============================] - ETA: 0s - loss: 0.1538 - acc: 0.9464\n","Epoch 00007: val_loss improved from 0.55857 to 0.52075, saving model to tmp_checkpoint.ckpt\n","63/63 [==============================] - 23s 367ms/step - loss: 0.1538 - acc: 0.9464 - val_loss: 0.5208 - val_acc: 0.7679\n","Epoch 8/25\n","63/63 [==============================] - ETA: 0s - loss: 0.1307 - acc: 0.9499\n","Epoch 00008: val_loss did not improve from 0.52075\n","63/63 [==============================] - 23s 362ms/step - loss: 0.1307 - acc: 0.9499 - val_loss: 0.7679 - val_acc: 0.6944\n","Epoch 9/25\n","63/63 [==============================] - ETA: 0s - loss: 0.1014 - acc: 0.9643\n","Epoch 00009: val_loss improved from 0.52075 to 0.41999, saving model to tmp_checkpoint.ckpt\n","63/63 [==============================] - 23s 365ms/step - loss: 0.1014 - acc: 0.9643 - val_loss: 0.4200 - val_acc: 0.8274\n","Epoch 10/25\n","63/63 [==============================] - ETA: 0s - loss: 0.0756 - acc: 0.9722\n","Epoch 00010: val_loss did not improve from 0.41999\n","63/63 [==============================] - 23s 358ms/step - loss: 0.0756 - acc: 0.9722 - val_loss: 0.4296 - val_acc: 0.8115\n","Epoch 11/25\n","63/63 [==============================] - ETA: 0s - loss: 0.1277 - acc: 0.9588\n","Epoch 00011: val_loss did not improve from 0.41999\n","63/63 [==============================] - 23s 367ms/step - loss: 0.1277 - acc: 0.9588 - val_loss: 0.7208 - val_acc: 0.6627\n","Epoch 12/25\n","63/63 [==============================] - ETA: 0s - loss: 0.0837 - acc: 0.9782\n","Epoch 00012: val_loss improved from 0.41999 to 0.25196, saving model to tmp_checkpoint.ckpt\n","63/63 [==============================] - 23s 365ms/step - loss: 0.0837 - acc: 0.9782 - val_loss: 0.2520 - val_acc: 0.9067\n","Epoch 13/25\n","63/63 [==============================] - ETA: 0s - loss: 0.0623 - acc: 0.9816\n","Epoch 00013: val_loss did not improve from 0.25196\n","63/63 [==============================] - 23s 363ms/step - loss: 0.0623 - acc: 0.9816 - val_loss: 0.3574 - val_acc: 0.8929\n","Epoch 14/25\n","63/63 [==============================] - ETA: 0s - loss: 0.0529 - acc: 0.9807\n","Epoch 00014: val_loss did not improve from 0.25196\n","63/63 [==============================] - 27s 434ms/step - loss: 0.0529 - acc: 0.9807 - val_loss: 0.6285 - val_acc: 0.7996\n","Epoch 15/25\n","63/63 [==============================] - ETA: 0s - loss: 0.0684 - acc: 0.9737\n","Epoch 00015: val_loss did not improve from 0.25196\n","63/63 [==============================] - 23s 366ms/step - loss: 0.0684 - acc: 0.9737 - val_loss: 0.4849 - val_acc: 0.7897\n","Epoch 16/25\n","63/63 [==============================] - ETA: 0s - loss: 0.0617 - acc: 0.9812\n","Epoch 00016: val_loss did not improve from 0.25196\n","63/63 [==============================] - 23s 365ms/step - loss: 0.0617 - acc: 0.9812 - val_loss: 0.5696 - val_acc: 0.7698\n","Epoch 17/25\n","63/63 [==============================] - ETA: 0s - loss: 0.0531 - acc: 0.9802\n","Epoch 00017: val_loss did not improve from 0.25196\n","63/63 [==============================] - 23s 366ms/step - loss: 0.0531 - acc: 0.9802 - val_loss: 0.8156 - val_acc: 0.6944\n","Epoch 18/25\n","63/63 [==============================] - ETA: 0s - loss: 0.0772 - acc: 0.9692\n","Epoch 00018: val_loss did not improve from 0.25196\n","63/63 [==============================] - 23s 369ms/step - loss: 0.0772 - acc: 0.9692 - val_loss: 0.3412 - val_acc: 0.8591\n","Epoch 19/25\n","63/63 [==============================] - ETA: 0s - loss: 0.0471 - acc: 0.9861\n","Epoch 00019: val_loss did not improve from 0.25196\n","63/63 [==============================] - 23s 368ms/step - loss: 0.0471 - acc: 0.9861 - val_loss: 0.7437 - val_acc: 0.7718\n","Epoch 20/25\n","63/63 [==============================] - ETA: 0s - loss: 0.0491 - acc: 0.9816\n","Epoch 00020: val_loss did not improve from 0.25196\n","63/63 [==============================] - 23s 369ms/step - loss: 0.0491 - acc: 0.9816 - val_loss: 0.6755 - val_acc: 0.7401\n","Epoch 21/25\n","63/63 [==============================] - ETA: 0s - loss: 0.0575 - acc: 0.9836\n","Epoch 00021: val_loss improved from 0.25196 to 0.19869, saving model to tmp_checkpoint.ckpt\n","63/63 [==============================] - 23s 368ms/step - loss: 0.0575 - acc: 0.9836 - val_loss: 0.1987 - val_acc: 0.9405\n","Epoch 22/25\n","63/63 [==============================] - ETA: 0s - loss: 0.0418 - acc: 0.9846\n","Epoch 00022: val_loss did not improve from 0.19869\n","63/63 [==============================] - 23s 372ms/step - loss: 0.0418 - acc: 0.9846 - val_loss: 0.3846 - val_acc: 0.8770\n","Epoch 23/25\n","63/63 [==============================] - ETA: 0s - loss: 0.0490 - acc: 0.9851\n","Epoch 00023: val_loss improved from 0.19869 to 0.16894, saving model to tmp_checkpoint.ckpt\n","63/63 [==============================] - 23s 365ms/step - loss: 0.0490 - acc: 0.9851 - val_loss: 0.1689 - val_acc: 0.9484\n","Epoch 24/25\n","63/63 [==============================] - ETA: 0s - loss: 0.0455 - acc: 0.9836\n","Epoch 00024: val_loss did not improve from 0.16894\n","63/63 [==============================] - 23s 367ms/step - loss: 0.0455 - acc: 0.9836 - val_loss: 0.4288 - val_acc: 0.8294\n","Epoch 25/25\n","63/63 [==============================] - ETA: 0s - loss: 0.0486 - acc: 0.9826\n","Epoch 00025: val_loss did not improve from 0.16894\n","63/63 [==============================] - 23s 365ms/step - loss: 0.0486 - acc: 0.9826 - val_loss: 0.3233 - val_acc: 0.8849\n"]}],"source":["history = model.fit(training_generator, \n","                    validation_data=(validation_generator),\n","                    epochs=epochs,\n","                    callbacks=[checkpoint],\n","                    )"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"aHolUvAPgIJK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643893794216,"user_tz":-540,"elapsed":9,"user":{"displayName":"JaeYoung Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08071223562055378805"}},"outputId":"330ae62e-80dd-4c46-a868-8a1e81f58114"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff7b7653610>"]},"metadata":{},"execution_count":12}],"source":["model.load_weights(checkpoint_path)"]}],"metadata":{"colab":{"name":"Category_3-CNN_TypeA.ipynb","provenance":[],"authorship_tag":"ABX9TyMmurTsbpg2f4DUnQf4POdI"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}